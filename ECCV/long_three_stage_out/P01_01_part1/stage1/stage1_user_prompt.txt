Analyze the provided 50 frames (uniformly sampled from one continuous video, chronological order). Treat the frames as the ONLY source of truth.

Goal: Generate a draft, step-by-step causal plan and step-level annotations for the entire video.

CRITICAL CONSTRAINT (Stage 1):
- Do NOT generate ANY keyframe-level fields.
- In particular, do NOT output `critical_frames`, `frame_index`, `interaction`, or `keyframe_image_path` anywhere.
- Do NOT reference frame/image indices or timestamps in any field (e.g., "Frame 12", "Image 12", "t=3.2s").

Language & grounding:
- Use objective, professional English.
- Use conservative naming (e.g., "container", "tool", "vegetable") when unsure.
- Do not hallucinate hidden states or off-screen objects.
- Keep the plan at a granularity that is realistic to localize with 50 sampled frames (prefer 4-7 steps; keep within 3-8).
- Use consistent object naming across all steps (do not rename the same object with different synonyms).
- Prefer `snake_case` for object identifiers in lists/fields (e.g., `objects`, `object_name`, `agent`, `patient`).
- Avoid placeholders like "unknown", "N/A", "..." â€” fill every field with grounded, specific content.

Output format (strict JSON only; no extra text):
{
  "high_level_goal": "One comprehensive English sentence describing the overall goal and intended final outcome of the entire video (focus on the final world state; do NOT list steps).",
  "steps": [
    {
      "step_id": 1,
      "step_goal": "A specific, action-oriented sub-goal for this step (unique across steps; chronological; no frame/time references).",
      "rationale": "Causal justification: why this step is necessary and what it enables for later steps (mechanistic, not narration).",
      "causal_chain": {
        "agent": "Primary force/controller for the WHOLE step (prefer body part like 'hands'/'right_hand'; use a tool part only if it is clearly the direct force applicator).",
        "action": "Concise verb phrase summarizing the core physical action for the WHOLE step (include the physical mechanism when helpful; e.g., 'apply torque to loosen', 'tilt to pour').",
        "patient": "Primary entity being acted upon in this step (`snake_case`; reuse the same identifier across all steps and lists).",
        "causal_precondition_on_spatial": [
          {
            "relation": "Short, mechanistic, visually verifiable spatial/physical relation token that MUST hold immediately before and throughout this step (prefer contact/support/grasp/containment/alignment/open/closed over vague text). `objects` must list the involved entities (`snake_case`), and `truth` indicates whether the relation holds. Examples: 'holding', 'contacting', 'on_top_of', 'inside', 'inserted_into', 'aligned_with', 'open', 'closed'.",
            "objects": ["object_a", "object_b"],
            "truth": true
          }
        ],
        "causal_precondition_on_affordance": [
          {
            "object_name": "Object whose functional affordance/state MUST already be true to execute this step (`snake_case`; grounded in visible evidence). `affordance_types` must be a non-empty list of short `snake_case` tokens, and `reasons` must justify them.",
            "affordance_types": ["affordance_a"],
            "reasons": "Grounded justification citing visible cues and why this affordance/state is required (no speculation)."
          }
        ],
        "causal_effect_on_spatial": [
          {
            "relation": "Short, concrete spatial/physical relation token that becomes true or false as a RESULT of this step (visually verifiable). Set `truth` to the post-step truth value (true = established, false = broken).",
            "objects": ["object_a", "object_b"],
            "truth": true
          }
        ],
        "causal_effect_on_affordance": [
          {
            "object_name": "Object whose functional affordance/state changes as a RESULT of this step (`snake_case`; grounded in visible evidence). `affordance_types` must be a non-empty list of short `snake_case` tokens, and `reasons` must justify them.",
            "affordance_types": ["affordance_a"],
            "reasons": "Grounded justification citing visible cues and the causal mechanism for the state change (no speculation)."
          }
        ]
      },
      "counterfactual_challenge_question": "A realistic what-if question that perturbs a physical precondition of this step (do NOT mention frame numbers).",
      "expected_challenge_outcome": "Predicted physical outcome (and why) for the challenge question.",
      "failure_reflecting": {
        "reason": "A plausible failure mode for this step (physical/procedural; grounded).",
        "recovery_strategy": "A concrete, actionable recovery strategy to still accomplish the step."
      }
    }
  ]
}

Additional constraints:
- Step ordering MUST follow the chronological order implied by the frames.
- `step_id` MUST start at 1 and increase by 1.
- Each `step_goal` must be non-empty, specific, and not duplicated across steps.
- Keep each `step_goal` concise and focused on a single sub-goal (prefer <= 12 words).
- `causal_chain.agent/action/patient` MUST be non-empty strings.
- `causal_chain.causal_precondition_on_spatial`, `causal_chain.causal_precondition_on_affordance`, `causal_chain.causal_effect_on_spatial`, `causal_chain.causal_effect_on_affordance` MUST be non-empty lists.
- `causal_chain.causal_precondition_on_affordance[*].reasons` and `causal_chain.causal_effect_on_affordance[*].reasons` MUST be non-empty grounded explanations.
- `counterfactual_challenge_question` and `expected_challenge_outcome` MUST be non-empty strings.
- `failure_reflecting.reason` and `failure_reflecting.recovery_strategy` MUST be non-empty strings.
- Ensure cross-step causal consistency: Step i `causal_effect_on_*` should make Step i+1 `causal_precondition_on_*` plausible (avoid contradictions).
- Do NOT add any extra keys beyond the schema above.
- Each step should be anchorable to visual evidence, but you are NOT selecting frames in this stage.

Silent self-check before you output:
- Strict valid JSON only (double quotes, no trailing commas, no markdown fences).
- No frame/image index references anywhere.
- All `truth` fields are JSON booleans (`true`/`false`), not strings.
- All list-typed fields (`steps`, `objects`, `affordance_types`, etc.) are JSON arrays (not single strings).
- Step count within 3-8 (preferred 4-7).
- No empty lists/strings for required fields; no placeholder values.
- No forbidden keys (`critical_frames`, `frame_index`, `interaction`, `keyframe_image_path`) anywhere.

The input frames are resized to approximately (1920x1080) pixels. Now output the final strict JSON object only.